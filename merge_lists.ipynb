{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_lists\n",
    "#\n",
    "# Merges the sea ice loss files using the \"mean removed\" and \"bwfitler\" methods into a combined file called \"allvriles\"\n",
    "#\n",
    "# Steven Cavallo\n",
    "# December 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import datetime as dt\n",
    "import os, datetime\n",
    "import matplotlib as mpl\n",
    "from pathlib import Path\n",
    "import gc\n",
    "\n",
    "from mstats import *\n",
    "import utilities_modules as um\n",
    "\n",
    "print(mpl.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath_datain = '/Users/scavallo/Documents/data/seaice_loss/paper_data_directory/'\n",
    "fpath_dataout = '/Users/scavallo/Documents/data/seaice_loss/paper_data_directory/'\n",
    "months_filter = [1,12]\n",
    "\n",
    "#months_filter = [3,5]\n",
    "#months_filter = [6,8]\n",
    "#months_filter = [9,11]\n",
    "#months_filter = [12,2]\n",
    "\n",
    "percentiles = [5,95] # For the data percentiles\n",
    "#percentiles = [100,100]\n",
    "dtUniqueCase = 1 # If set to 1, will not count back-to-back daily events as separate events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ( (months_filter[0] == 1) & (months_filter[1] == 12) ):\n",
    "    timeframe = 'annual'\n",
    "if ( (months_filter[0] == 3) & (months_filter[1] == 5) ):\n",
    "    timeframe = 'mam'\n",
    "if ( (months_filter[0] == 6) & (months_filter[1] == 8) ):\n",
    "    timeframe = 'jja'\n",
    "if ( (months_filter[0] == 9) & (months_filter[1] == 11) ):\n",
    "    timeframe = 'son'\n",
    "if ( (months_filter[0] == 12) & (months_filter[1] == 2) ):\n",
    "    timeframe = 'djf'\n",
    "\n",
    "if dtUniqueCase == 0:\n",
    "    dtname = ''    \n",
    "else:\n",
    "    dtname = '_dtUnique0' + str(dtUniqueCase)\n",
    "\n",
    "percentilenum = percentiles[0] + (100-percentiles[1])\n",
    "percstr = str(percentilenum) + 'percentile'\n",
    "\n",
    "filtname = 'bwfilter'\n",
    "fname_list1 = 'rapid_seaice_loss_events_int_withboth_' + timeframe + '_' + filtname + '_3d_' +percstr +  dtname +'.dat'\n",
    "filtname = 'meanremoved'\n",
    "fname_list2 = 'rapid_seaice_loss_events_int_withboth_' + timeframe + '_' + filtname + '_3d_' +percstr +  dtname +'.dat'\n",
    "filtname = 'allvriles'\n",
    "newfile = 'rapid_seaice_loss_events_int_withboth_' + timeframe + '_' + filtname + '_3d_' +percstr +  dtname +'.dat'\n",
    "\n",
    "\n",
    "fpath_list1 = fpath_datain + fname_list1\n",
    "fpath_list2 = fpath_datain + fname_list2\n",
    "newfile_path = fpath_dataout + newfile\n",
    "\n",
    "#event_fname_out = 'rapid_seaice_loss_events_int_withboth_' + timeframe + '_' + filtname + '_3d_' +percstr +  dtname +'.dat'\n",
    "#print(event_fname_out)\n",
    "#event_path_out = event_dir_out + event_fname_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/scavallo/Documents/data/seaice_loss/paper_data_directory/rapid_seaice_loss_events_int_withboth_annual_bwfilter_3d_100percentile.dat\n",
      "/Users/scavallo/Documents/data/seaice_loss/paper_data_directory/rapid_seaice_loss_events_int_withboth_annual_meanremoved_3d_100percentile.dat\n"
     ]
    }
   ],
   "source": [
    "# read cases\n",
    "print(fpath_list1)\n",
    "aa = np.loadtxt(fpath_list1, skiprows=0)       \n",
    "datelist_list1 = aa[:,0].astype(int)\n",
    "dextent_in_list1 = aa[:,1]\n",
    "dextent_in_nofilt_list1 = aa[:,2]\n",
    "\n",
    "print(fpath_list2)\n",
    "bb = np.loadtxt(fpath_list2, skiprows=0)       \n",
    "datelist_list2 = bb[:,0].astype(int)\n",
    "dextent_in_list2 = bb[:,1]\n",
    "dextent_in_nofilt_list2 = bb[:,2]\n",
    "\n",
    "test = list(set(datelist_list1).intersection(datelist_list2))\n",
    "\n",
    "\n",
    "# These are the indices in datelist_list1 that also occur somewhere in datelist_list2\n",
    "commondates = datelist_list1[np.nonzero(np.in1d(datelist_list1, datelist_list2))]\n",
    "[inds] = np.nonzero(np.in1d(datelist_list1, datelist_list2))\n",
    "#print(commondates)\n",
    "#print(inds)\n",
    "#print(datelist_list1[inds])\n",
    "\n",
    "dumval = -9999\n",
    "if 1 == 0:\n",
    "    outfile = open(newfile_path,'w+')\n",
    "    nvalues_file1 = len(datelist_list1)\n",
    "    nvalues_file2 = len(datelist_list2)\n",
    "    nvalues_total = nvalues_file1 + nvalues_file2\n",
    "    nvalues_merged = nvalues_total - len(inds)\n",
    "    datelist_merged = []\n",
    "    values_nofilt_merged = []\n",
    "    counter = 0\n",
    "    indcounter = 0\n",
    "    for ii in range(0,nvalues_total):\n",
    "        #print(ii,nvalues_total)\n",
    "        if ii < nvalues_file2:\n",
    "            #print(datelist_list2[counter])\n",
    "            outfile.write('%-10s %7.4f %7.4f\\n' % (datelist_list2[counter], dumval, dextent_in_nofilt_list2[counter]))\n",
    "            if ii == nvalues_file2-1:\n",
    "                counter = -1\n",
    "        else:  \n",
    "            if indcounter < len(inds): \n",
    "                if counter != inds[indcounter]:\n",
    "                    #print(datelist_list1[counter])\n",
    "                    outfile.write('%-10s %7.4f %7.4f\\n' % (datelist_list1[counter], dumval, dextent_in_nofilt_list1[counter]))\n",
    "                else:\n",
    "                    #print(counter,indcounter)\n",
    "                    indcounter += 1\n",
    "            else:\n",
    "                outfile.write('%-10s %7.4f %7.4f\\n' % (datelist_list1[counter], dumval, dextent_in_nofilt_list1[counter]))\n",
    "        counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No filter\n",
    "if 1 == 0:\n",
    "    outfile = open(newfile_path,'w+')\n",
    "    nvalues_file1 = len(datelist_list1)\n",
    "    nvalues_file2 = len(datelist_list2)\n",
    "    nvalues_total = nvalues_file1 + nvalues_file2\n",
    "    nvalues_merged = nvalues_total - len(inds)\n",
    "    datelist_merged = []\n",
    "    values_nofilt_merged = []\n",
    "    counter = 0\n",
    "    indcounter = 0\n",
    "    for ii in range(0,nvalues_file1):\n",
    "        #print(ii,indcounter)\n",
    "        #if ( (ii <= len(inds)) & (ii == inds[indcounter])):\n",
    "        #    indcounter+=1\n",
    "        #else:\n",
    "        outfile.write('%-10s %7.4f %7.4f\\n' % (datelist_list1[counter], dumval, dextent_in_nofilt_list1[counter]))\n",
    "        counter+=1\n",
    "    counter = 0\n",
    "    for ii in range(0,nvalues_file2):\n",
    "        outfile.write('%-10s %7.4f %7.4f\\n' % (datelist_list2[counter], dumval, dextent_in_nofilt_list2[counter]))\n",
    "        counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No repeated dates\n",
    "if 1 == 1:\n",
    "    outfile = open(newfile_path,'w+')\n",
    "    nvalues_file1 = len(datelist_list1)\n",
    "    nvalues_file2 = len(datelist_list2)\n",
    "    nvalues_total = nvalues_file1 + nvalues_file2\n",
    "    nvalues_merged = nvalues_total - len(inds)\n",
    "    datelist_merged = []\n",
    "    values_nofilt_merged = []\n",
    "    counter = 0\n",
    "    indcounter = 0\n",
    "\n",
    "    datelist_list1_arr = np.array(datelist_list1).astype('i')\n",
    "    datelist_list2_arr = np.array(datelist_list2).astype('i')\n",
    "    \n",
    "    \n",
    "    datelist_combined = np.concatenate([datelist_list1_arr,datelist_list2_arr])\n",
    "    datelist_out, indices = np.unique(datelist_combined , return_index=True)\n",
    "    \n",
    "    dextent_combined = np.concatenate([dextent_in_nofilt_list1,dextent_in_nofilt_list2])\n",
    "    dextent_nofilt_combined = dextent_combined[indices]\n",
    "    \n",
    "    #datelist_union = np.union1d( datelist_list1_arr,datelist_list2_arr)\n",
    "    \n",
    "    counter = 0\n",
    "    for ii in range(0,len(datelist_out)):\n",
    "        outfile.write('%-10s %7.4f %7.4f\\n' % (str(datelist_out[counter]), dumval, dextent_nofilt_combined[counter]))\n",
    "        counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
